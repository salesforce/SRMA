# Improving Contrastive Learning with Model Augmentation
The paper is avaliable online in [arxiv](https://arxiv.org/abs/2203.15508)

## Introduction
This is the repo for paper 'Improving Contrastive Learning via Model Augmentation'. In this paper, we argue existing data augmentation methods for contrastive learning have the following weakness:
1) optimal data augmentation methods are hard to devise,
2) data augmentation methods destroy sequential correlations, 
3) data augmentation fails to incorporate comprehensive self-supervised signals. 
Therefore, we proposed three type of model augmentation methods: `neuron masking`, `layer dropping` and `encoder complementing`.
